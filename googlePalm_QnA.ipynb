{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8eaaacf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain-google-genai\n",
      "  Downloading langchain_google_genai-0.0.5-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting google-generativeai<0.4.0,>=0.3.1 (from langchain-google-genai)\n",
      "  Downloading google_generativeai-0.3.2-py3-none-any.whl.metadata (5.9 kB)\n",
      "Requirement already satisfied: langchain-core<0.2,>=0.1 in c:\\users\\deepi\\anaconda3\\lib\\site-packages (from langchain-google-genai) (0.1.3)\n",
      "Collecting google-ai-generativelanguage==0.4.0 (from google-generativeai<0.4.0,>=0.3.1->langchain-google-genai)\n",
      "  Downloading google_ai_generativelanguage-0.4.0-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: google-auth in c:\\users\\deepi\\anaconda3\\lib\\site-packages (from google-generativeai<0.4.0,>=0.3.1->langchain-google-genai) (2.6.0)\n",
      "Collecting google-api-core (from google-generativeai<0.4.0,>=0.3.1->langchain-google-genai)\n",
      "  Downloading google_api_core-2.15.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\deepi\\anaconda3\\lib\\site-packages (from google-generativeai<0.4.0,>=0.3.1->langchain-google-genai) (4.9.0)\n",
      "Requirement already satisfied: protobuf in c:\\users\\deepi\\anaconda3\\lib\\site-packages (from google-generativeai<0.4.0,>=0.3.1->langchain-google-genai) (3.19.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\deepi\\anaconda3\\lib\\site-packages (from google-generativeai<0.4.0,>=0.3.1->langchain-google-genai) (4.62.3)\n",
      "Collecting proto-plus<2.0.0dev,>=1.22.3 (from google-ai-generativelanguage==0.4.0->google-generativeai<0.4.0,>=0.3.1->langchain-google-genai)\n",
      "  Downloading proto_plus-1.23.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting protobuf (from google-generativeai<0.4.0,>=0.3.1->langchain-google-genai)\n",
      "  Downloading protobuf-4.25.1-cp39-cp39-win_amd64.whl.metadata (541 bytes)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\deepi\\anaconda3\\lib\\site-packages (from langchain-core<0.2,>=0.1->langchain-google-genai) (6.0)\n",
      "Requirement already satisfied: anyio<5,>=3 in c:\\users\\deepi\\anaconda3\\lib\\site-packages (from langchain-core<0.2,>=0.1->langchain-google-genai) (4.2.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\deepi\\anaconda3\\lib\\site-packages (from langchain-core<0.2,>=0.1->langchain-google-genai) (1.33)\n",
      "Requirement already satisfied: langsmith<0.1.0,>=0.0.63 in c:\\users\\deepi\\anaconda3\\lib\\site-packages (from langchain-core<0.2,>=0.1->langchain-google-genai) (0.0.74)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in c:\\users\\deepi\\anaconda3\\lib\\site-packages (from langchain-core<0.2,>=0.1->langchain-google-genai) (23.2)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\users\\deepi\\anaconda3\\lib\\site-packages (from langchain-core<0.2,>=0.1->langchain-google-genai) (2.5.2)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\deepi\\anaconda3\\lib\\site-packages (from langchain-core<0.2,>=0.1->langchain-google-genai) (2.26.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in c:\\users\\deepi\\anaconda3\\lib\\site-packages (from langchain-core<0.2,>=0.1->langchain-google-genai) (8.2.3)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\deepi\\anaconda3\\lib\\site-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1->langchain-google-genai) (3.2)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\deepi\\anaconda3\\lib\\site-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1->langchain-google-genai) (1.2.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\deepi\\anaconda3\\lib\\site-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1->langchain-google-genai) (1.2.0)\n",
      "Collecting googleapis-common-protos<2.0.dev0,>=1.56.2 (from google-api-core->google-generativeai<0.4.0,>=0.3.1->langchain-google-genai)\n",
      "  Downloading googleapis_common_protos-1.62.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting google-auth (from google-generativeai<0.4.0,>=0.3.1->langchain-google-genai)\n",
      "  Downloading google_auth-2.25.2-py2.py3-none-any.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\deepi\\anaconda3\\lib\\site-packages (from google-auth->google-generativeai<0.4.0,>=0.3.1->langchain-google-genai) (5.0.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\deepi\\anaconda3\\lib\\site-packages (from google-auth->google-generativeai<0.4.0,>=0.3.1->langchain-google-genai) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\deepi\\anaconda3\\lib\\site-packages (from google-auth->google-generativeai<0.4.0,>=0.3.1->langchain-google-genai) (4.8)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\deepi\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2,>=0.1->langchain-google-genai) (2.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: pyodbc 4.0.0-unsupported has a non-standard version number. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pyodbc or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\deepi\\anaconda3\\lib\\site-packages (from pydantic<3,>=1->langchain-core<0.2,>=0.1->langchain-google-genai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.5 in c:\\users\\deepi\\anaconda3\\lib\\site-packages (from pydantic<3,>=1->langchain-core<0.2,>=0.1->langchain-google-genai) (2.14.5)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\deepi\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain-core<0.2,>=0.1->langchain-google-genai) (1.26.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\deepi\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain-core<0.2,>=0.1->langchain-google-genai) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\deepi\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain-core<0.2,>=0.1->langchain-google-genai) (2.0.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\deepi\\anaconda3\\lib\\site-packages (from tqdm->google-generativeai<0.4.0,>=0.3.1->langchain-google-genai) (0.4.4)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in c:\\users\\deepi\\anaconda3\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-ai-generativelanguage==0.4.0->google-generativeai<0.4.0,>=0.3.1->langchain-google-genai) (1.43.0)\n",
      "Collecting grpcio-status<2.0.dev0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-ai-generativelanguage==0.4.0->google-generativeai<0.4.0,>=0.3.1->langchain-google-genai)\n",
      "  Downloading grpcio_status-1.60.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\deepi\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth->google-generativeai<0.4.0,>=0.3.1->langchain-google-genai) (0.4.8)\n",
      "Requirement already satisfied: six>=1.5.2 in c:\\users\\deepi\\anaconda3\\lib\\site-packages (from grpcio<2.0dev,>=1.33.2->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-ai-generativelanguage==0.4.0->google-generativeai<0.4.0,>=0.3.1->langchain-google-genai) (1.16.0)\n",
      "Collecting grpcio<2.0dev,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0->google-ai-generativelanguage==0.4.0->google-generativeai<0.4.0,>=0.3.1->langchain-google-genai)\n",
      "  Downloading grpcio-1.60.0-cp39-cp39-win_amd64.whl.metadata (4.2 kB)\n",
      "Downloading langchain_google_genai-0.0.5-py3-none-any.whl (14 kB)\n",
      "Downloading google_generativeai-0.3.2-py3-none-any.whl (146 kB)\n",
      "   ---------------------------------------- 146.9/146.9 kB 2.2 MB/s eta 0:00:00\n",
      "Downloading google_ai_generativelanguage-0.4.0-py3-none-any.whl (598 kB)\n",
      "   ---------------------------------------- 598.7/598.7 kB 2.1 MB/s eta 0:00:00\n",
      "Downloading google_api_core-2.15.0-py3-none-any.whl (121 kB)\n",
      "   ---------------------------------------- 122.0/122.0 kB 2.4 MB/s eta 0:00:00\n",
      "Downloading google_auth-2.25.2-py2.py3-none-any.whl (184 kB)\n",
      "   ---------------------------------------- 184.2/184.2 kB 3.7 MB/s eta 0:00:00\n",
      "Downloading protobuf-4.25.1-cp39-cp39-win_amd64.whl (413 kB)\n",
      "   ---------------------------------------- 413.4/413.4 kB 3.7 MB/s eta 0:00:00\n",
      "Downloading googleapis_common_protos-1.62.0-py2.py3-none-any.whl (228 kB)\n",
      "   ---------------------------------------- 228.7/228.7 kB 4.6 MB/s eta 0:00:00\n",
      "Downloading proto_plus-1.23.0-py3-none-any.whl (48 kB)\n",
      "   ---------------------------------------- 48.8/48.8 kB ? eta 0:00:00\n",
      "Downloading grpcio_status-1.60.0-py3-none-any.whl (14 kB)\n",
      "Downloading grpcio-1.60.0-cp39-cp39-win_amd64.whl (3.7 MB)\n",
      "   ---------------------------------------- 3.7/3.7 MB 3.7 MB/s eta 0:00:00\n",
      "Installing collected packages: protobuf, grpcio, proto-plus, googleapis-common-protos, google-auth, grpcio-status, google-api-core, google-ai-generativelanguage, google-generativeai, langchain-google-genai\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 3.19.1\n",
      "    Uninstalling protobuf-3.19.1:\n",
      "      Successfully uninstalled protobuf-3.19.1\n",
      "  Attempting uninstall: grpcio\n",
      "    Found existing installation: grpcio 1.43.0\n",
      "    Uninstalling grpcio-1.43.0:\n",
      "      Successfully uninstalled grpcio-1.43.0\n",
      "  Attempting uninstall: google-auth\n",
      "    Found existing installation: google-auth 2.6.0\n",
      "    Uninstalling google-auth-2.6.0:\n",
      "      Successfully uninstalled google-auth-2.6.0\n",
      "Successfully installed google-ai-generativelanguage-0.4.0 google-api-core-2.15.0 google-auth-2.25.2 google-generativeai-0.3.2 googleapis-common-protos-1.62.0 grpcio-1.60.0 grpcio-status-1.60.0 langchain-google-genai-0.0.5 proto-plus-1.23.0 protobuf-3.19.4\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain-google-genai\n",
    "!pip install instructorembedding\n",
    "!pip install huggingface\n",
    "!pip install --upgrade huggingface_hub\n",
    "!pip install -U sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b433e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import GoogleGenerativeAI\n",
    "#Use langchain_google_genai.GoogleGenerativeAI instead.\n",
    "api_key = \"AIzaSyCC2pFam7_gLQY_MBNEMu8Zpjlwi02t578\"\n",
    "llm = GoogleGenerativeAI(model=\"models/text-bison-001\", google_api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c855ff4a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Samosas, oh samosas**\n",
      "**So crispy, so flaky, so delicious**\n",
      "**I could eat them all day long**\n",
      "**My one true love**\n"
     ]
    }
   ],
   "source": [
    "poem = llm(\"Write a 4 line poem of my love for samosa\")\n",
    "print(poem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11ae3cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain.embeddings import GooglePalmEmbeddings\n",
    "from langchain.llms import GooglePalm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "663aa20c",
   "metadata": {},
   "source": [
    "### loading data from Codebasics FAQ csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9bf5398",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders.csv_loader import CSVLoader\n",
    "\n",
    "loader = CSVLoader(file_path='codebasics_faqs.csv', source_column=\"prompt\")\n",
    "\n",
    "# Store the loaded data in the 'data' variable\n",
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e12a0b1",
   "metadata": {},
   "source": [
    "### Hugging Face Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5cc5af87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import HuggingFaceInstructEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6a2359bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings import HuggingFaceInstructEmbeddings\n",
    "# Initialize instructor embeddings using the Hugging Face model\n",
    "instructor_embeddings = HuggingFaceInstructEmbeddings(model_name=\"hkunlp/instructor-large\")\n",
    "e = instructor_embeddings.embed_query(\"What is your refund policy?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6eb809ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b48b693f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.043898068368434906,\n",
       " 0.007685533724725246,\n",
       " -0.009231905452907085,\n",
       " 0.024496253579854965,\n",
       " 0.03359227627515793]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c5e90d",
   "metadata": {},
   "source": [
    "As you can see above, embedding for a sentance \"What is your refund policy\" is a list of size 768. Looking at the numbers in this list, doesn't give any intuitive understanding of what it is but just assume that these numbers are capturing the meaning of \"What is your refund policy\". If you are curious to know about embeddings, go to youtube and search \"codebasics word embeddings\" and you will find bunch of videos with simple, intuitive explanations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d88b43",
   "metadata": {},
   "source": [
    "### Vector store using FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e594168",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "# Create a FAISS instance for vector database from 'data'\n",
    "vectordb = FAISS.from_documents(documents=data,\n",
    "                                 embedding=instructor_embeddings)\n",
    "\n",
    "# Create a retriever for querying the vector database\n",
    "retriever = vectordb.as_retriever(score_threshold = 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be931897",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdocs = retriever.get_relevant_documents(\"how about job placement support?\")\n",
    "rdocs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "334d5145",
   "metadata": {},
   "source": [
    "### Create RetrievalQA chain along with prompt template ðŸš€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e64f7f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_template = \"\"\"Given the following context and a question, generate an answer based on this context only.\n",
    "In the answer try to provide as much text as possible from \"response\" section in the source document context without making much changes.\n",
    "If the answer is not found in the context, kindly state \"I don't know.\" Don't try to make up an answer.\n",
    "\n",
    "CONTEXT: {context}\n",
    "\n",
    "QUESTION: {question}\"\"\"\n",
    "\n",
    "\n",
    "PROMPT = PromptTemplate(\n",
    "    template=prompt_template, input_variables=[\"context\", \"question\"]\n",
    ")\n",
    "chain_type_kwargs = {\"prompt\": PROMPT}\n",
    "\n",
    "\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "chain = RetrievalQA.from_chain_type(llm=llm,\n",
    "                            chain_type=\"stuff\",\n",
    "                            retriever=retriever,\n",
    "                            input_key=\"query\",\n",
    "                            return_source_documents=True,\n",
    "                            chain_type_kwargs=chain_type_kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e28ed68",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain('Do you provide job assistance and also do you provide job gurantee?')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
